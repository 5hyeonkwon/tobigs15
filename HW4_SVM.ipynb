{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HyMvTfrPTEU"
   },
   "source": [
    "#### TOBIG'S 14기 정규세션 4주차 SVM \n",
    "### ASSIGNMENT1. Multiclass SVM 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMqxwjbRNX6u",
    "outputId": "f7b6519f-9521-446b-a107-044a7113bc08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         setosa\n",
      "1         setosa\n",
      "2         setosa\n",
      "3         setosa\n",
      "4         setosa\n",
      "         ...    \n",
      "145    virginica\n",
      "146    virginica\n",
      "147    virginica\n",
      "148    virginica\n",
      "149    virginica\n",
      "Name: species, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "#IRIS 데이터 로드\n",
    "iris =  sns.load_dataset('iris') \n",
    "X= iris.iloc[:,:4] #학습할데이터\n",
    "y = iris.iloc[:,-1] #타겟\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tm8gpfVSNX67"
   },
   "outputs": [],
   "source": [
    "scal = StandardScaler() #scaling\n",
    "X = scal.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "laRcz10bNX7C",
    "outputId": "66f6f6c2-38fb-4da2-bb76-560838244c24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         setosa\n",
      "1         setosa\n",
      "2         setosa\n",
      "3         setosa\n",
      "4         setosa\n",
      "         ...    \n",
      "145    virginica\n",
      "146    virginica\n",
      "147    virginica\n",
      "148    virginica\n",
      "149    virginica\n",
      "Name: species, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7VgXR-SNX7K"
   },
   "outputs": [],
   "source": [
    "# One VS Rest 구현을 위해 1) class가 0 or not 2)class가 1 or not을 구분하기 위한 머신 등을 미리 만들어주자\n",
    "svm_1 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm_2 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm_3 = SVC(kernel ='rbf', C = 5, gamma = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyMSHOFHNX7R"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #test/train 데이터로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KnlaqAJNX7X"
   },
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train) #one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9S5ML8x1NX7d",
    "outputId": "598fe774-41b4-4552-b7f6-b2a650e57897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0]\n",
      "[-1.12470845 -0.86326953 -0.65281099 -0.50248821 -0.76284323 -0.87465573\n",
      "  1.07709345 -0.99281647  0.47441336 -0.99842743 -0.83989348  0.15633457\n",
      "  0.32871788 -0.97965464 -0.72385083 -0.92638376  1.28322481 -0.56240455\n",
      " -0.72719892 -0.99509775  0.43166724 -0.96451557 -0.82991366 -1.03020581\n",
      " -0.75166835  1.13461335  0.39943974 -1.04194106 -0.93376548 -1.06133798]\n"
     ]
    }
   ],
   "source": [
    "svm_1.fit(X_train,y_train.iloc[:,0]) # 데이터 클레스가 0 or not 구분해주는 머신\n",
    "svm_2.fit(X_train,y_train.iloc[:,1]) # 데이터 클레스가 1 or not 구분해주는 머신\n",
    "svm_3.fit(X_train,y_train.iloc[:,2]) # 데이터 클레스가 2 or not 구분해주는 머신\n",
    "print(svm_1.predict(X_test)) #데이터 클래스가 0 or not을 구분해주는 애를 통해서 테스트 데이터의 클래스가 0인지, 0이 아닌인지 예측해보자\n",
    "\n",
    "print(svm_1.decision_function(X_test)) #decision_function hyperplane과의 거리를 구하는 방법(필요하다면 활용해주세요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5024882107322184, -0.36987092513822756, -0.13070947139128608)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_1.decision_function(X_test)[3], svm_2.decision_function(X_test)[3], svm_3.decision_function(X_test)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCR46aMrNX7p",
    "outputId": "ec7adcec-d0e8-4dd8-f2df-4cd063a19867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "17\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# 부호가 모든 같은 경우가 있는가? > 모두 동점인 경우가 생길 것\n",
    "for i in range(len(X_test)):\n",
    "    # ~. decision_function을 이용하면 해당 데이터가 하이퍼플레인으로부터 얼마나 떨어져있는지 '거리'가 나온다!\n",
    "    # 다음은 그 값의 부호를 이용해 모두가 동점인 경우가 있는지 출력하는 함수 \n",
    "    if (np.sign(svm_1.decision_function(X_test)[i]) == np.sign(svm_2.decision_function(X_test)[i])) and (np.sign(svm_2.decision_function(X_test)[i]) == np.sign(svm_3.decision_function(X_test)[i])):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Case 1 : One vs Rest SVM을 이부분에 구현해주세요 위 결과들을 이용해서 multi class SVM을 직접 구현해주세요! 하드코딩이 하시기 편할겁니다.\n",
    "\n",
    "def one_vs_rest_svm(X,y) :\n",
    "    pred_classes = np.zeros((len(X),3))\n",
    "    length = len(X)\n",
    "    y_label = {0 : 'setosa', 1 : 'versicolor', 2 : 'virginica'}\n",
    "    results = []\n",
    "    \n",
    "    # 3개의 분류기 중 결과값이 1인 분류기에 +1을 하여 진행 \n",
    "    for i in range(length)  :\n",
    "        if svm_1.predict(X)[i] == 1 :\n",
    "            pred_classes[i][0] += 1\n",
    "        elif svm_2.predict(X)[i] == 1 :\n",
    "            pred_classes[i][1] += 1\n",
    "        elif svm_3.predict(X)[i] == 1 :\n",
    "            pred_classes[i][2] += 1\n",
    "        \n",
    "        # 0 : 0 : 0 인 경우 decision_function을 이용하여 가까운 거리의 경우 그 분류 값에 해당하게 설정을 한다. \n",
    "        if pred_classes[i][0] == pred_classes[i][1] and pred_classes[i][1] == pred_classes[i][2] :\n",
    "            results.append(np.argmax([svm_1.decision_function(X)[i], svm_2.decision_function(X)[i], svm_3.decision_function(X)[i]]))\n",
    "        else :\n",
    "            results.append(np.argmax(pred_classes[i]))\n",
    "        \n",
    "    \n",
    "    results = [y_label.get(i) for i in results]    \n",
    "    \n",
    "    #print(pred_classes)\n",
    "    print(results)\n",
    "    \n",
    "    \n",
    "    score = accuracy_score(y, results)\n",
    "    \n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 one vs rest svm의 경우 분류기 하나씩 투표를 하여 가장 많이 나오는 경우 해당 class를 부여하는 방식으로 진행하였다.\n",
    "- 예외의 경우 0 : 0 : 0 일 때는 argmax한 결과 0번째 index가 나와 올바르게 분류하기 힘듦으로 decision_function을 이용하여 거리를 비교하여 argmax를 진행하는데\n",
    "- 이러한 방식을 이용하여 밑의 코드와 같이 간단하게 정리할 수  있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_rest_svm_1(X,y) :\n",
    "    length = len(X)\n",
    "    y_label = {0 : 'setosa', 1 : 'versicolor', 2 : 'virginica'}\n",
    "    results = []\n",
    "    \n",
    "    \n",
    "    for i in range(length)  :\n",
    "            results.append(np.argmax([svm_1.decision_function(X)[i], svm_2.decision_function(X)[i], svm_3.decision_function(X)[i]]))\n",
    "        \n",
    "    \n",
    "    results = [y_label.get(i) for i in results]    \n",
    "    \n",
    "    \n",
    "    print(results)\n",
    "    \n",
    "    \n",
    "    score = accuracy_score(y, results)\n",
    "    \n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'setosa', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'versicolor', 'versicolor', 'setosa', 'versicolor', 'virginica', 'virginica', 'setosa', 'virginica', 'versicolor', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'virginica', 'versicolor']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_vs_rest_svm(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'setosa', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'versicolor', 'versicolor', 'setosa', 'versicolor', 'virginica', 'virginica', 'setosa', 'virginica', 'versicolor', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'virginica', 'versicolor']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_vs_rest_svm_1(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위와 아래의 결과가 같음을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2 : One vs One SVM을 이 부분에 구현해주세요. (선택사항)\n",
    "\n",
    "# 'setosa', 'virginica', 'versicolor' 세 class에 대하여 분류를 해야 하기 때문에 \n",
    "# 데이터 셋을 setosa vs virginca / setosa vs vesicolor / virginica vs versicolor로 나누어야 한다.\n",
    "# 그래서 다음과 같이 함수를 지정하였다.\n",
    "def get_new_data(X,y,class_1, class_2) :\n",
    "    idx_1 = y_train[class_1] == 1\n",
    "    idx_2 = y_train[class_2] == 1\n",
    "    \n",
    "    new_y = np.concatenate((y[idx_1][class_1],y[idx_2][class_1]))\n",
    "    \n",
    "    new_X = np.vstack((X[idx_1],X[idx_2]))\n",
    "    \n",
    "    return new_X, new_y\n",
    "    \n",
    "    \n",
    "\n",
    "def one_vs_one_svm(X_train, y_train, X_test, y_test) :\n",
    "    columns = list(y_train.columns)\n",
    "    svm_clfs = []\n",
    "    for i in range(len(columns)) :\n",
    "        for j in range(i+1,len(columns)) :\n",
    "            # 새로운 데이터셋에 대하여 각각 svm을 돌려 class를 예측한다.\n",
    "            # 이경우 3개의 분류값이 존재하므로 총 3C2 개수의 분류기를 생성하여 저장한다.\n",
    "            new_X, new_y = get_new_data(X_train, y_train, columns[i], columns[j])\n",
    "\n",
    "            svm = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "\n",
    "            svm.fit(new_X, new_y)\n",
    "            svm_clfs.append([svm, columns[i], columns[j]])\n",
    "\n",
    "    pred_classes = np.zeros((len(X_test),3))\n",
    "    length = len(X_test)\n",
    "\n",
    "    y_label = {0 : 'setosa', 1 : 'versicolor', 2 : 'virginica'}\n",
    "    r_y_label = {'setosa' : 0, 'versicolor' : 1, 'virginica' : 2}\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # test 데이터를 각각 분류기에 적용시켜 해당하는 class에 +1을 지정해준다. \n",
    "    # 편의상 columns 순성에 맞게 0 : setosa, 1 : versicolor, 2 : virginica를 해주어 가장 큰 값을 지니면 해당 index의 label를 return 해준다.\n",
    "    for k in range(length) :\n",
    "        for l in range(len(svm_clfs)) :\n",
    "            svm, c1, c2 = svm_clfs[l]\n",
    "            pred = svm.predict([X_test[k]])\n",
    "\n",
    "            if pred == 1 :\n",
    "                pred_classes[k][r_y_label.get(c1)] += 1\n",
    "            else :\n",
    "                pred_classes[k][r_y_label.get(c2)] += 1\n",
    "        \n",
    "        # 모두 1 : 1 : 1 로 같은 경우를 고려하여  desicion_function을 적용하여 return해준다.\n",
    "        if pred_classes[k][0] == pred_classes[k][1] and pred_classes[k][1] == pred_classes[k][2] :\n",
    "            results.append(np.argmax([svm_clfs[0][0].decision_function([X_test[k]]), svm_clfs[1][0].decision_function([X_test[k]]), svm_clfs[2][0].decision_function([X_test[k]])]))\n",
    "        else :\n",
    "            results.append(np.argmax(pred_classes[k]))\n",
    "\n",
    "\n",
    "    results = [y_label.get(i) for i in results]  \n",
    "    \n",
    "    print(results)\n",
    "\n",
    "    score = accuracy_score(y_test, results)\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'setosa', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'versicolor', 'versicolor', 'setosa', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'versicolor', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'virginica', 'versicolor']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_vs_one_svm(X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlVlC9l9NX77",
    "outputId": "46f7603d-a673-498e-8a9e-a0cb79cc9468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor' 'versicolor' 'versicolor' 'virginica' 'virginica'\n",
      " 'virginica' 'setosa' 'virginica' 'setosa' 'versicolor' 'virginica'\n",
      " 'setosa' 'setosa' 'virginica' 'versicolor' 'versicolor' 'setosa'\n",
      " 'virginica' 'virginica' 'virginica' 'setosa' 'virginica' 'versicolor'\n",
      " 'versicolor' 'virginica' 'setosa' 'setosa' 'virginica' 'virginica'\n",
      " 'versicolor']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원래 라이브러리가 제공하는 multi class SVM과 여러분이 구현한 multiclass SVM 결과를 비교해주세요\n",
    "from sklearn.model_selection import train_test_split #데이터셋 분리\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, y, test_size=0.2, random_state=48)\n",
    "\n",
    "svm_4 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm_4.fit(X_train_2, y_train_2)\n",
    "y_pred = svm_4.predict(X_test_2)\n",
    "\n",
    "print(y_pred)\n",
    "accuracy_score(y_test_2,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vb6hpOPQNX8B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'setosa', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'versicolor', 'versicolor', 'setosa', 'versicolor', 'virginica', 'virginica', 'setosa', 'virginica', 'versicolor', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'virginica', 'versicolor']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_vs_rest_svm_1(X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'setosa', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'versicolor', 'versicolor', 'setosa', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'versicolor', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'virginica', 'versicolor']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_2 = pd.get_dummies(y_train_2)\n",
    "\n",
    "one_vs_one_svm(X_train_2, y_train_2, X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과를 비교해보면 one vs one svm은 동일한 결과가 나오는 반면에 one vs rest svm은 보다 좋은 성능이 나오는 것을 확인할 수 있다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "assignment_1.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
